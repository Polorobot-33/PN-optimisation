{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48722106-3093-4262-9b53-afa2f433bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b4fbd8-9e4b-4a0e-ac64-ebf274ccf8b6",
   "metadata": {},
   "source": [
    "# 1 - Etude du problème d'optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2334692f-58de-48fb-8baa-b50654e76461",
   "metadata": {},
   "source": [
    "**Question 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b15bce3-803c-4197-a3be-4ee866937f64",
   "metadata": {},
   "source": [
    "Le coût (2) représente les revenus de la boulangerie. En effet, le terme $v^T min \\lbrace q, d \\rbrace $ représente son chiffre d'affaire, avec $min \\lbrace q, d \\rbrace $ le vecteur des quantités effectivement vendues de chaque produit (si $d>q$, une partie de la demande n'est pas comblée, tandis que si $d<q$, une partie des produits n'est pas écoulée). Le terme $c^T r$, quant à lui, représente les coûts de production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf699c3-e802-4671-9993-466367801c57",
   "metadata": {},
   "source": [
    "**Question 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e907082a-169e-4d62-b83f-bd72ae84bb91",
   "metadata": {},
   "source": [
    "Le terme $min \\lbrace q, d \\rbrace$ induit une difficulté dans la recherche de maximum car il est non différentiable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f0ccb3-1c57-403e-92c3-7ab5896f3f0e",
   "metadata": {},
   "source": [
    "**Question 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15799767-1899-447c-aaae-e2d1629a439e",
   "metadata": {},
   "source": [
    "On pose, pour tout $i\\le p$, $h_i(q,d)=\\frac {q_i e^{-\\alpha q_i}+d_i e^{-\\alpha d_i}}{e^{-\\alpha q_i}+e^{-\\alpha d_i}}$ avec $\\alpha$ constante positive. \n",
    "\n",
    "On a alors, pour tout q, pour tout d : $h_i(q,d)=\\frac {q_i e^{-\\alpha (q_i-d_i)}+d_i}{e^{-\\alpha (q_i-d_i)}+1}$\n",
    "\n",
    "Si on fixe q et d et qu'on fait tendre $\\alpha$ vers $+\\infty$, on a :\n",
    "\n",
    "Cas 1 : $q_i\\ge d_i$, alors $h_i(q,d)$ tend vers $d_i$\n",
    "\n",
    "Cas 2 : $q_i<d_i$, alors $h_i(q,d)$ tend vers $q_i$\n",
    "\n",
    "On en déduit que $h_i$ tend, lorsque $\\alpha$ tend vers $+\\infty$, vers $min(q_i,d_i)$\n",
    "\n",
    "Pour $\\alpha \\gg 1$, on en déduit donc que $h$ forme une bonne approximation de la fonction $(q,d)\\mapsto (min(q,d))$\n",
    "\n",
    "La fonction $h$ a par ailleurs la particularité d'être différentiable en tout point de $\\mathbb{R}^{2p}$, ce qui nous sera utile dans la recherche d'extrémum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c33b35c4-198d-4aa9-9eea-e530a4640165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(q, d) :\n",
    "    return (q*np.exp(-alpha*q) + d*np.exp(-alpha*d)) / (np.exp(-alpha*q) + np.exp(-alpha*d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad3febb-ddde-4ce7-bae4-a84dc1517f70",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "  On s'intéresse donc au problème d'optimisation suivant : \n",
    "\n",
    "  $$\\min_{\\begin{align} Aq-r \\leq 0 \\\\ -q \\leq 0 \\\\ -r \\leq 0   \\end{align}} (c^Tr-v^Th(q,d))$$\n",
    "\n",
    "  Où les variables de décisions sont les : q la quantité produite, et r la quantité de matières premières achetée. Cela peut être modélisé par un vecteur de $\\R^{m+p}$.\n",
    "\n",
    "  Les trois contraintes listées représentent respectivement : les quantités minimales de matières premières pour produire les quantités q de produits, le fait de vendre des produits et non d'en acheter, et de même, le fait que l'on ne puisse pas vendre des matières premières. Cette dernière condition est facultative si on fait l'hypothèse tout les coefficients de A son positifs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0da8c1e-7983-422e-91cd-ba96a0ef7feb",
   "metadata": {},
   "source": [
    "# 2 - Etude et résolution numérique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dd0e23-2277-402a-afdc-f1e538f74886",
   "metadata": {},
   "source": [
    "**Question 5**\n",
    "\n",
    "Nous avons affaire à un problème d'optimisation de $\\R^{m+p}$ dans $\\R$ avec des contraintes linéaires.\n",
    "\n",
    "De plus, nous allons considérer que la fonction h est concave composante par composante. Ce n'est rigoureusement pas le cas, mais une vérification numérique de l'allure des courbes confirme cette approximation pour des valeurs élevées de alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae85157-f5c8-4567-9c3d-24532f80088a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabaf5b43f0c4cb78b61f5f3a0faafb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='d', max=10.0, min=-10.0), IntSlider(value=1, descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_h(d = 0, alpha_ = 1) :\n",
    "    global alpha\n",
    "    alpha = alpha_\n",
    "    \n",
    "    x = np.linspace(d-5, d+5, 100)\n",
    "    y = h(x, d)\n",
    "    min_y = [min(varx, d) for varx in x]\n",
    "    plt.plot(x, y, label=\"h(x, d)\")\n",
    "    plt.plot(x, min_y, label=\"min(x, d)\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.title(\"comparaison de h(d, x) et min(d, x)\")\n",
    "    plt.legend()\n",
    "\n",
    "interact(test_h, d=(-10, 10, 0.1), alpha=(0.5, 10, 0.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b859509-1403-4fe5-8471-e3ab69d78af4",
   "metadata": {},
   "source": [
    "La fonction à minimiser est donc une fonction convexe en tant que somme d'une fonction affine et d'une fonction convexe. Cela nous permet d'envisager des méthodes de recherche de point selle somme les algorithmes d'Uzawa ou d'Arrow-Hurwicz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a749042c-9ae4-46ee-aaa9-a8605ee61c9a",
   "metadata": {},
   "source": [
    "**Question 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d7ce11-424c-4165-b949-58065566ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 5\n",
    "p = 3\n",
    "\n",
    "alpha = 0.1\n",
    "c = 1e-3 * np.array([30, 1, 1.3, 4, 1])\n",
    "v = np.array([0.9, 1.5, 1.1])\n",
    "d = np.array([400, 67, 33])\n",
    "A = np.array([[3.5, 2,   1 ],\n",
    "              [250, 80,  25],\n",
    "              [0,   8,   3 ],\n",
    "              [0,   40,  10],\n",
    "              [0,   8.5, 0 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24bd0fd1-8a31-434f-80d8-94441fedef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(grand_vecteur) :\n",
    "    q = grand_vecteur[:p]\n",
    "    r = grand_vecteur[p:]\n",
    "    return np.dot(c, r) - np.dot(v, h(q, d))\n",
    "\n",
    "def lagrangien(grand_vecteur, lambda_):\n",
    "    #print(str(fun(grand_vecteur) - np.dot(lambda_, contraintes(grand_vecteur))) + \", \" + str(fun(grand_vecteur)) + \", \" + str(np.dot(lambda_, contraintes(grand_vecteur))))\n",
    "    return fun(grand_vecteur) - np.dot(lambda_, contraintes(grand_vecteur))\n",
    "\n",
    "def contraintes(grand_vecteur):\n",
    "    q = grand_vecteur[:p]\n",
    "    r = grand_vecteur[p:]\n",
    "    \n",
    "    const = np.zeros(2*m+p)\n",
    "    const[:m] = r - np.dot(A, q)\n",
    "    const[m:2*m] = r\n",
    "    const[-p:] = q\n",
    "\n",
    "    # Les contraintes sont ici inversées car les algorithmes d'optimisation de scipy utilisent la convention ci(x) >= 0\n",
    "    return const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb079bc-1c0b-4c17-8709-1c68b9d7911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uzawa(x0, lambda_0, alpha_uzawa, f, c):\n",
    "    x = x0\n",
    "    l = lambda_0\n",
    "    prev_x = x0 + np.ones(len(x0))\n",
    "    mybounds = [(-100, 2000) for elem in x0]\n",
    "    # Les contraintes servent ici à guider le solveur SLSQP pour qu'il n'y ait pas d'évaluation de h avec des valeurs trop élevées,\n",
    "    # mais elles ne doivent pas interférer avec la véritable résolution.\n",
    "    \n",
    "    while np.linalg.norm(x - prev_x) > 0.1 :\n",
    "        prev_x = x\n",
    "        x = (optimize.minimize(f, x, args=l, method='SLSQP', bounds = mybounds)).x\n",
    "        l = np.maximum(l - alpha_uzawa*c(x), 0)\n",
    "    return x,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33eed306-3818-48c1-ae8d-e631716501bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q : [-100. -100. -100.]\n",
      "r : [2000. 2000. 2000. 2000. 2000.]\n"
     ]
    }
   ],
   "source": [
    "x0 = np.zeros(m+p)\n",
    "lambda_0 = np.ones(2*m+p)\n",
    "alpha_uzawa = 0.1\n",
    "alpha = 0.1\n",
    "\n",
    "x, l = uzawa(x0, lambda_0, alpha_uzawa, lagrangien, contraintes)\n",
    "print(\"q : \" + str(x[:p]))\n",
    "print(\"r : \" + str(x[p:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9f4491-b1df-40c5-bbc4-625ef06c5a26",
   "metadata": {},
   "source": [
    "Malheureusement, on se rend compte que le résultat n'est pas satisfaisant, et que le solveur ne donne pas des quantités acceptables. Une des raisons de cet échec peut être l'initialisation des variables comme x0 ou lambda_0, ou le fait que notre fonction h n'est pas exactement convexe.\n",
    "\n",
    "\n",
    "Nous allons plutôt utiliser les méthodes offertes par la librairie scipy.optimize :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8acba62b-b046-4080-ba8e-2b3a6fa59128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3fc9c8b4ec74f8094e4c922fcf76a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='alpha_interact', max=2.0, min=0.05, step=0.05), Outp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f(alpha_interact) :\n",
    "    global alpha\n",
    "    alpha = alpha_interact\n",
    "    x0 = np.zeros(m+p)\n",
    "    x = optimize.minimize(fun, x0, method='SLSQP', constraints={'type':'ineq', 'fun':contraintes}, options={'maxiter':1000, 'disp':True}).x\n",
    "    print(\"q : \" + str(x[:p]))\n",
    "    print(\"r : \" + str(x[p:]))\n",
    "\n",
    "interact(f, alpha_interact = (0.05, 2, 0.05));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba313ac-42ec-45bf-8897-9a2c3f31c956",
   "metadata": {},
   "source": [
    "Cette fois-ci, l'agorithme nous donne des valeurs plus judicieuses, et qui correspondent à l'intuition (à savoir vendre autant que la demande et acheter les quantités en consequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e241c02-36fd-44f2-a8d0-1872c479d53e",
   "metadata": {},
   "source": [
    "**Question 7**\n",
    "\n",
    "***a)***\n",
    "\n",
    "On cherche ici à maximiser l'espérance du profit : $\\sum_{k=1}^K \\pi_k (v^T h(q, d_k) - c^T r)$\n",
    "Le problème devient donc le suivant : \n",
    "\n",
    "  $$\\min_{\\begin{align} Aq-r \\leq 0 \\\\ -q \\leq 0 \\\\ -r \\leq 0   \\end{align}} \\sum_{k=1}^K \\pi_k (c^T r - v^T h(q, d_k))$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22bded41-4af4-4a8b-87ee-7f3b6536e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = np.array([400, 67, 33])\n",
    "d2 = np.array([500, 80, 53])\n",
    "d3 = np.array([300, 60, 43])\n",
    "\n",
    "proba = [(d1, 0.5), (d2, 0.3), (d3, 0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdef7943-43b7-43c7-ab0b-ff30911d5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_proba(grand_vecteur) :\n",
    "    q = grand_vecteur[:p]\n",
    "    r = grand_vecteur[p:]\n",
    "    scenarii = [p * (np.dot(c, r) - np.dot(v, h(q, d))) for (d, p) in proba]\n",
    "    return np.sum(scenarii)\n",
    "\n",
    "def lagrangien_proba(grand_vecteur, lambda_):\n",
    "    #print(str(fun(grand_vecteur) - np.dot(lambda_, contraintes(grand_vecteur))) + \", \" + str(fun(grand_vecteur)) + \", \" + str(np.dot(lambda_, contraintes(grand_vecteur))))\n",
    "    return fun_proba(grand_vecteur) - np.dot(lambda_, contraintes(grand_vecteur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe9e0355-e2ac-411f-b395-af7fed450da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aea69ed1c3d4bfd83c17d33215d7c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='alpha_interact', max=2.0, min=0.05, step=0.05), Outp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f2(alpha_interact) :\n",
    "    global alpha\n",
    "    alpha = alpha_interact\n",
    "    x0 = np.zeros(m+p)\n",
    "    x = optimize.minimize(fun_proba, x0, method='SLSQP', constraints={'type':'ineq', 'fun':contraintes}, options={'maxiter':1000, 'disp':True}).x\n",
    "    print(\"q : \" + str(x[:p]))\n",
    "    print(\"r : \" + str(x[p:]))\n",
    "\n",
    "interact(f2, alpha_interact = (0.05, 2, 0.05));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbd11be-d02d-49b7-be94-6cf66541e0af",
   "metadata": {},
   "source": [
    "On remarque que les résultats ont l'air assez stables en fonction de alpha, et semblent se rapprocher des valeurs q=[400, 80, 53]. On remarque aussi qu'ils ne semblent pas résulter de la moyenne des différentes demandes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb65f1e7-aa28-431e-be9d-7524bfb3904b",
   "metadata": {},
   "source": [
    "# 3 - Etude du problème non-régularisé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b106ca76-7081-4ad7-a194-ad2f5097c20a",
   "metadata": {},
   "source": [
    "**Question 8**\n",
    "\n",
    "***a)***\n",
    "Le problème d'optimisation est le suivant :\n",
    "  $$\\min_{\\begin{align} Aq-r \\leq 0 \\\\ -q \\leq 0 \\\\ -r \\leq 0   \\end{align}} \\sum_{k=1}^K \\pi_k (c^T r - v^T min(q, d_k)))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc68ec7c-827e-4118-8854-8e78e5a876b3",
   "metadata": {},
   "source": [
    "***b)***\n",
    "Mq Aq = r à l'optimum\n",
    "\n",
    "Supposons que $\\exists i_0, \\; (Aq)_{i_0} < r_{i_0}$\n",
    "\n",
    "Notre problème est un problème d'optimisation convexe à contraintes affines d'ensemble admissible non vide, donc il existe une solution à ce problème. Notons $(q^*, r^*)$ les quantités à l'optimum.\n",
    "\n",
    "Considérons $(\\hat{r}, q^*)$ tel que $$\\hat{r}_i = r^*_i \\;si\\; i \\neq i_0,  \\\\  \\hat{r}_i = \\frac{r^*_i + (Aq)_i}{2} \\;si\\; i = i_0$$\n",
    "On vérifie aisément que $(\\hat{r}, q^*)$ vérifie les contraintes, et on a également $c^T\\hat{r} < c^T r^*$, donc le profit total est plus élevé. Cela implique que $f(\\hat{r}, q^*) < f(r^*, q^*)$ (en notant f la fonction à minimiser de notre problème tel que défini en a). ). On aboutit à une contradiction car $\\forall (q, r) \\in \\R^p\\times\\R^m\\; f(r, q) < f(r^*, q^*)$ par définition de $(r^*, q^*)$.\n",
    "\n",
    "On en déduit que la contrainte (1) doit être active."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa63c36-f2aa-42ac-abcd-c6b3329ade00",
   "metadata": {},
   "source": [
    "**c)** À l'équilibre, r est donc entièrement déterminé par q avec la relation $Aq=r$.\n",
    "\n",
    "On peut donc réécrire le problème d'optimisation sous la forme :\n",
    "$$\\min_{\\begin{align} -q \\leq 0 \\end{align}} \\sum_{k=1}^K \\pi_k (c^T Aq - v^T min(q, d_k))$$\n",
    "\n",
    "La condition $-r\\le 0$, c'est-à-dire $-Aq\\le 0$ est impliquée par la condition $-q\\le 0$.\n",
    "\n",
    "De plus, on observe que $c^T A-v^T<0$ et $d\\ge 0$, ce qui fait que lrosqu'on prend un coefficient de $q$ négatif, la situation est moins optimale que lorsqu'on remplace ce coefficient négatif par un zéro. La condition $-q\\le 0$ n'a donc pas d'influence sur la recherche de minimum ici. Le problème se réécrit donc :\n",
    "$$\\min_{\\begin{align} q \\end{align}} \\sum_{k=1}^K \\pi_k (c^T Aq - v^T min(q, d_k))$$\n",
    "\n",
    "On obtient un problème d'optimisation sans contrainte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b7e323-2fe6-43b2-8bdd-b54d831c4ba2",
   "metadata": {},
   "source": [
    "**Question 9**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ed50b-fc85-4c82-936d-5b9dd4a9a0e9",
   "metadata": {},
   "source": [
    "**a)** On a :\n",
    "\n",
    "$$\\max_{\\begin{align} u_k\\le d_k, u_k\\le q \\end{align}}(v^T u_k)=\\max_{\\begin{align} u_k\\le \\min\\lbrace d,q\\rbrace \\end{align}}(v^T u_k)$$\n",
    "\n",
    "Or $v\\ge 0$ donc lorsqu'on maximise $v^T u_k$, la contrainte inégalité sera active, ce qui devient : $\\max{v^T \\min\\lbrace d,q \\rbrace}$.\n",
    "\n",
    "Il y a donc équivalence entre ces deux problèmes d'optimisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b9c97-c855-4ff2-9750-5e0da33aea38",
   "metadata": {},
   "source": [
    "**b)** Le problème d'optimisation de la question 8 devient alors :\n",
    "\n",
    "$$\\min_{\\begin{align} q,u_k\\\\ u_k\\le d_k \\\\ u_k\\le q \\end{align}} \\sum_{k=1}^K \\pi_k (c^T Aq - v^T u_k)$$\n",
    "\n",
    "Cette nouvelle formulation présente l'avantage d'être différentiable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de1bef1-9f26-49b1-bd08-74a1e924385a",
   "metadata": {},
   "source": [
    "**c)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fe0a4e8-03f9-4b0b-9199-7dc96b92fb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -414.89000000204305\n",
      "            Iterations: 32\n",
      "            Function evaluations: 416\n",
      "            Gradient evaluations: 32\n",
      "u= [400.  67.  33. 500.  67.   0.   0.   0.   0.] et q= [500.  67.  33.]\n",
      "Bénéfice : 414.89000000204305 euros\n"
     ]
    }
   ],
   "source": [
    "d1=np.array([400,67,33])\n",
    "d2=np.array([500,80,53])\n",
    "d3=np.array([300,60,43])\n",
    "pi=np.array([0.5,0.3,0.2])\n",
    "\n",
    "def contraintes_2(UQ):\n",
    "    u=UQ[0:9]\n",
    "    q=UQ[9:12]\n",
    "    C=np.zeros(18)\n",
    "    for i in range(3):\n",
    "        C[i]=d1[i]-u[i]\n",
    "        C[i+3]=q[i]-u[i]\n",
    "        C[i+6]=d2[i]-u[i+3]\n",
    "        C[i+9]=q[i]-u[i+3]\n",
    "        C[i+12]=d3[i]-u[i+6]\n",
    "        C[i+15]=q[i]-u[i+6]\n",
    "    return C\n",
    "def fonction(UQ):\n",
    "    u=UQ[0:9]\n",
    "    q=UQ[9:12]\n",
    "    s=0\n",
    "    for i in range(3):\n",
    "        uk=u[i:i+3]\n",
    "        s+=pi[i]*(np.dot(np.dot(np.transpose(c),A),q)-np.dot(np.transpose(v),uk))\n",
    "    return s\n",
    "\n",
    "x0 = np.zeros(12)\n",
    "x = optimize.minimize(fonction, x0, method='SLSQP', constraints={'type':'ineq', 'fun':contraintes_2}, options={'maxiter':1000, 'disp':True}).x\n",
    "print(\"u=\",x[:9], \"et q=\",x[9:12])\n",
    "print(\"Bénéfice :\",-fonction(x),\"euros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d027a94-87eb-489b-bda8-d42b93615237",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cce54e13-1981-40c7-9f18-d4c05dc5882f",
   "metadata": {},
   "source": [
    "On remarque que l'on a un bénéfice plus important (414€ contre 319€ précédemment) en regardant la valeur exacte de la fonction, et pas une valeur approchée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45946c7b-c84f-4963-b82d-07fdd7bfcd0a",
   "metadata": {},
   "source": [
    "**Question 10**\n",
    "\n",
    "Pour résoudre ce problème de manière non lisse, on peut utiliser un algorithme du point proximal. Implémentons-le ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e2cac41-b2c3-4701-b75d-84ffe1b3a167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([400.00275653, 438.94529228, 676.26822486]),\n",
       " np.float64(-142.48718454813223))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D=np.array([d1,d2,d3])\n",
    "def fonction2(q):\n",
    "    s=0\n",
    "    for i in range(3):\n",
    "        mini=np.zeros(3)\n",
    "        for j in range(3):\n",
    "            mini[j]=min(q[j],D[i][j])\n",
    "        s+=pi[i]*(np.dot(np.dot(np.transpose(c),A),q)-np.dot(np.transpose(v),mini))\n",
    "    return s\n",
    "\n",
    "def prox(q,l):\n",
    "    derivee=np.zeros(3)\n",
    "    for i in range(3):\n",
    "        mini=q<D[i]\n",
    "        derivee+=pi[i]*(np.dot(np.transpose(c),A)-np.dot(np.transpose(v),mini))\n",
    "    s=q-l*derivee\n",
    "    return s\n",
    "\n",
    "def grad_proximal():\n",
    "    q=np.array([0,0,0])\n",
    "    l=100\n",
    "    for n in range(1,10000):\n",
    "        q=prox(q,l)\n",
    "        l=100/n\n",
    "    return q,fonction2(q)\n",
    "grad_proximal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4710f65-db35-4759-854b-e7a2e5051edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d1a7f2-33d1-41a8-9336-2f73af246596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
